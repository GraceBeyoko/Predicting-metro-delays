{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 245,
   "id": "3a7b75c8-77e6-4f8a-b6fa-43e26160a076",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import libraries\n",
    "import requests\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "import os\n",
    "import html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "id": "f252aae8-65d5-4975-84a6-820929be139b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#download dataset\n",
    "df_lines = pd.read_csv('./Online_Data/referentiel-des-lignes.csv', sep=';')\n",
    "stops_data = pd.read_csv('./Online_Data/arrets.csv', sep=';')\n",
    "delays_metro = pd.read_csv(\"./Collected_Data/metro_delays.csv\")\n",
    "delays_rer = pd.read_csv(\"./Collected_Data/rail_delays.csv\")\n",
    "metro_incident = pd.read_csv(\"./Collected_Data/metro_line_reports.csv\")\n",
    "rer_incident = pd.read_csv(\"./Collected_Data/rer_line_reports.csv\")\n",
    "trafic2023_ratio = pd.read_csv(\"./Online_Data/validations-1er-semestre.csv\", sep=';')\n",
    "trafic2023_raw = pd.read_csv(\"./Online_Data/validations-reseau.csv\", sep=\";\")\n",
    "gas = pd.read_csv(\"./Online_Data/prix-des-carburants-en-france-flux-instantane-v2.csv\", sep=\";\") #needs cleaning/filtering\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "id": "e1d30d5c-4b20-4ae6-b52b-4ed202aa4cf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#create filter\n",
    "stops_filter = [22086, 463013, 22136, 462993, 21964, 462969, 22125, 463113, 41295, 473921, 473993, 41354, 474060, 474061]\n",
    "name_filter = [\"CH.D.G.ETOILE\", \"CHATELET\", \"SAINT-LAZARE\",\"ST-GERM.D.PRES\", \"BLANCHE\",\"AVENUE DU PRESIDENT KENNEDY\",\"BUNO GIRONVILLE\",\"MASSY PALAISEAU\"]\n",
    "lines_filter = [\"C01371\", \"C01372\", \"C01374\" ,\" C01382\", \"C01742\", \"C01743\", \"C01727\", \"C0172\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "id": "b5fc7e94",
   "metadata": {},
   "outputs": [],
   "source": [
    "#clean dataset\n",
    "line_refs = df_lines[(~df_lines['TransportSubmode'].isin(['suburbanRailway', 'regionalRail', 'railShuttle']))]\n",
    "line_refs = line_refs[['ID_Line', 'TransportMode', 'Name_Line']]\n",
    "line_refs = line_refs.sort_values(by='ID_Line')\n",
    "\n",
    "stops_data = stops_data[stops_data['ArRType'].isin(['metro', 'rail'])]\n",
    "stops_data = stops_data.sort_values(by=['ArRType', 'ArRId'])\n",
    "stops_data = stops_data[['ArRId', 'ArRName', 'ArRType', 'ArRTown']]\n",
    "\n",
    "metro_incident['ref'] = metro_incident['ref'].str.replace('stop_point:IDFM:', '', regex=False)\n",
    "metro_incident['ref'] = metro_incident['ref'].str.replace('line:IDFM:', '', regex=False)\n",
    "metro_incident['ref'] = metro_incident['ref'].str.replace('stop_area:IDFM:', '', regex=False)\n",
    "metro_incident['message_text'] = metro_incident['message_text'].str.replace('<p>', '', regex=False)\n",
    "metro_incident['message_text'] = metro_incident['message_text'].str.split('</p>').str[0]\n",
    "metro_incident['message_text'] = metro_incident['message_text'].str.replace('<br>', '', regex=False) \n",
    "metro_incident = metro_incident[metro_incident[\"channel_name\"].isin([\"moteur\"])]\n",
    "metro_incident = metro_incident.drop_duplicates(subset=[\"disruption_id\"])\n",
    "metro_incident.drop(['tags', 'category', 'updated_at', 'channel_name'], axis=1, inplace=True) \n",
    "\n",
    "rer_incident['ref'] = rer_incident['ref'].str.replace('stop_point:IDFM:', '', regex=False)\n",
    "rer_incident['ref'] = rer_incident['ref'].str.replace('line:IDFM:', '', regex=False)\n",
    "rer_incident['ref'] = rer_incident['ref'].str.replace('stop_area:IDFM:', '', regex=False)\n",
    "rer_incident['message_text'] = rer_incident['message_text'].str.replace('<p>', '', regex=False)\n",
    "rer_incident['message_text'] = rer_incident['message_text'].str.replace('</p>', '', regex=False)\n",
    "rer_incident['message_text'] = rer_incident['message_text'].str.replace('<br>', '', regex=False) \n",
    "rer_incident['message_text'] = rer_incident['message_text'].apply(html.unescape)\n",
    "rer_incident = rer_incident[rer_incident[\"channel_name\"].isin([\"moteur\"])]\n",
    "rer_incident = rer_incident.drop_duplicates(subset=[\"disruption_id\"])\n",
    "rer_incident.drop(['tags', 'category', 'updated_at', 'channel_name'], axis=1, inplace=True) \n",
    "\n",
    "delays_metro.drop(['scheduled_arrival','scheduled_departure','arrival_difference','departure_difference'], axis=1, inplace=True) #inplace allows to actually modify the original datset without having to reassing with \"=\"\"\n",
    "delays_metro['line_ref'] = delays_metro['line_ref'].str.replace('STIF:Line::', '', regex=False).str.rstrip(':')\n",
    "\n",
    "mapping = dict(zip(name_filter, stops_filter))\n",
    "trafic2023_ratio['LIBELLE_ARRET_REA'] = trafic2023_ratio['LIBELLE_ARRET'].replace(mapping)\n",
    "trafic2023_ratio.drop([\"lda\"],axis=1, inplace=True)\n",
    "\n",
    "trafic2023_raw['LIBELLE_ARRET_REA'] = trafic2023_raw['LIBELLE_ARRET'].replace(mapping)\n",
    "trafic2023_raw.drop([\"lda\"],axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "id": "69302686",
   "metadata": {},
   "outputs": [],
   "source": [
    "#filter dataset\n",
    "stops_data = stops_data[stops_data['ArRId'].isin(stops_filter)]\n",
    "\n",
    "metro_incident = metro_incident[\n",
    "    metro_incident['ref'].isin(map(str, stops_filter + lines_filter))\n",
    "]\n",
    "\n",
    "rer_incident = rer_incident[\n",
    "    rer_incident['ref'].isin(map(str, stops_filter + lines_filter))\n",
    "]\n",
    "\n",
    "trafic2023_ratio = trafic2023_ratio[trafic2023_ratio['LIBELLE_ARRET_REA'].isin(stops_filter)]\n",
    "\n",
    "trafic2023_raw = trafic2023_raw[trafic2023_raw['LIBELLE_ARRET_REA'].isin(stops_filter)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "id": "afadb29f-88b3-4e5e-a454-3d0d6cc7fd77",
   "metadata": {},
   "outputs": [],
   "source": [
    "#merge dataset\n",
    "merged_metro = pd.merge(delays_metro, stops_data, left_on='stop_reference', right_on='ArRId')\n",
    "merged_metro.drop(['ArRId', 'ArRName', 'ArRType', 'transport_mode', 'recorded_at_time'], axis=1, inplace=True) \n",
    "\n",
    "merged_rer = pd.merge(delays_rer, stops_data, left_on='stop_reference', right_on='ArRId')\n",
    "merged_rer.drop(['ArRId', 'ArRName', 'ArRType', 'transport_mode', 'recorded_at_time'],  axis=1, inplace=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
