{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3a7b75c8-77e6-4f8a-b6fa-43e26160a076",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import libraries\n",
    "import requests\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "import os\n",
    "import html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "9dfacd7b-e322-4702-a42d-fc89b2d1e45f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Add trafic2023_ratio or raw somewhere?\n",
    "##Add holidays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f252aae8-65d5-4975-84a6-820929be139b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#download dataset\n",
    "df_lines = pd.read_csv(\"./Online_Data/referentiel-des-lignes.csv\", sep=';')\n",
    "stops_data = pd.read_csv(\"./Online_Data/arrets.csv\", sep=';')\n",
    "\n",
    "trafic2023_ratio = pd.read_csv(\"./Online_Data/validations-1er-semestre.csv\", sep=';')\n",
    "trafic2023_raw = pd.read_csv(\"./Online_Data/validations-reseau.csv\", sep=\";\")\n",
    "\n",
    "hourly_weather = pd.read_csv(\"./Online_Data/Weather/hourly_weather.csv\")\n",
    "minutely_15_weather = pd.read_csv(\"./Online_Data/Weather/minutely_15_weather.csv\")\n",
    "\n",
    "delays_metro = pd.read_csv(\"./Collected_Data/metro_delays.csv\")\n",
    "delays_rer = pd.read_csv(\"./Collected_Data/rail_delays.csv\")\n",
    "onTime_metro = pd.read_csv(\"./Collected_Data/metro_onTime.csv\")\n",
    "onTime_rer = pd.read_csv(\"./Collected_Data/rail_onTime.csv\")\n",
    "\n",
    "metro_incident = pd.read_csv(\"./Collected_Data/metro_line_reports.csv\")\n",
    "rer_incident = pd.read_csv(\"./Collected_Data/rer_line_reports.csv\")\n",
    "#gas = pd.read_csv(\"./Online_Data/prix-des-carburants-en-france-flux-instantane-v2.csv\", sep=\";\") #needs cleaning/filtering"
   ]
  },
  {
   "cell_type": "raw",
   "id": "73911c10-6959-43fd-86de-8e9accba3298",
   "metadata": {},
   "source": [
    "## fix christmas holidays and creaate day variable for full datasets\n",
    "\n",
    "df_holidays = pd.read_csv(\"data/df_vacances.csv\", sep = \";\")\n",
    "df_bank_holidays = pd.read_csv(\"data/df_jours_feries.csv\", encoding=\"latin1\", sep=\";\")\n",
    "df_holidays = df_holidays.drop(\"vacances_noel\", axis = 1)  ## wrong variable, to delete and recreate\n",
    "\n",
    "df_bank_holidays[\"day\"] = pd.to_datetime(df_bank_holidays[\"date\"])\n",
    "df_holidays[\"day\"] = pd.to_datetime(df_holidays[\"date\"])\n",
    "\n",
    "df_with_holidays = df_bank_holidays.merge(df_holidays, on = \"day\", how = \"inner\")\n",
    "df_with_holidays[\"is_bank_holiday\"] = (df_with_holidays[\"nom_vacances\"]).notna().astype(int)\n",
    "df_with_holidays[\"is_weekend\"]= df_with_holidays[\"day\"].dt.weekday.isin([5,6]).astype(int)\n",
    "df_with_holidays[\"saturday\"]= (df_with_holidays[\"day\"].dt.weekday == 5).astype(int)\n",
    "df_with_holidays[\"sunday\"]=  (df_with_holidays[\"day\"].dt.weekday == 6).astype(int)\n",
    "df_with_holidays[\"is_weekend_or_bank_holiday\"] = df_with_holidays[[\"is_weekend\", \"is_bank_holiday\"]].max(axis=1)\n",
    "#df_with_holidays[\"summer\"]=  df_with_holidays[\"day\"].dt.month.isin([6,7,8,9]).astype(int)\n",
    "df_with_holidays[\"winter\"]=  df_with_holidays[\"day\"].dt.month.isin([11, 12, 1, 2]).astype(int)\n",
    "df_with_holidays[\"holidays\"] = (df_with_holidays[\"vacances_zone_a\"] + df_with_holidays[\"vacances_zone_b\"] + df_with_holidays[\"vacances_zone_c\"])/3\n",
    "df_with_holidays[\"small_holidays\"]=df_with_holidays[\"nom_vacances\"].isin([\"Vacances de la Toussaint\",\"Vacances de printemps\",\"Pont de l'Ascension\"]).astype(int)\n",
    "df_with_holidays[\"christmas_holidays\"]=(df_with_holidays[\"nom_vacances\"].str.contains(\"No\")).fillna(False).astype(int)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e1d30d5c-4b20-4ae6-b52b-4ed202aa4cf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#create filter\n",
    "stops_filter = [22086, 463013, 22136, 462993, 21964, 462969, 22125, 463113, 41295, 473921, 473993, 41354, 474060, 474061]\n",
    "name_filter = [\"CH.D.G.ETOILE\", \"CHATELET\", \"SAINT-LAZARE\",\"ST-GERM.D.PRES\", \"BLANCHE\",\"AVENUE DU PRESIDENT KENNEDY\",\"BUNO GIRONVILLE\",\"MASSY PALAISEAU\"]\n",
    "lines_filter = [\"C01371\", \"C01372\", \"C01374\" ,\" C01382\", \"C01742\", \"C01743\", \"C01727\", \"C0172\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b5fc7e94",
   "metadata": {},
   "outputs": [],
   "source": [
    "#clean dataset\n",
    "line_refs = df_lines[(~df_lines['TransportSubmode'].isin(['suburbanRailway', 'regionalRail', 'railShuttle']))]\n",
    "line_refs = line_refs[['ID_Line', 'TransportMode', 'Name_Line']]\n",
    "line_refs = line_refs.sort_values(by='ID_Line')\n",
    "\n",
    "stops_data = stops_data[stops_data['ArRType'].isin(['metro', 'rail'])]\n",
    "stops_data = stops_data.sort_values(by=['ArRType', 'ArRId'])\n",
    "stops_data = stops_data[['ArRId', 'ArRName', 'ArRType', 'ArRTown']]\n",
    "\n",
    "def cleaning_message(df):\n",
    "    df['ref'] = df['ref'].str.replace('stop_point:IDFM:', '', regex=False)\n",
    "    df['ref'] = df['ref'].str.replace('line:IDFM:', '', regex=False)\n",
    "    df['ref'] = df['ref'].str.replace('stop_area:IDFM:', '', regex=False)\n",
    "    df['message_text'] = df['message_text'].str.replace('<p>', '', regex=False)\n",
    "    df['message_text'] = df['message_text'].str.replace('<br>', '', regex=False) \n",
    "    df = df[df[\"channel_name\"].isin([\"moteur\"])]\n",
    "\n",
    "cleaning_message(metro_incident)\n",
    "cleaning_message(rer_incident)\n",
    "\n",
    "metro_incident['message_text'] = metro_incident['message_text'].str.split('</p>').str[0]\n",
    "metro_incident.drop_duplicates(subset=[\"disruption_id\"], inplace=True)\n",
    "metro_incident.drop(['tags', 'category', 'updated_at', 'channel_name'], axis=1, inplace=True) \n",
    "\n",
    "rer_incident['message_text'] = rer_incident['message_text'].str.replace('</p>', '', regex=False)\n",
    "rer_incident['message_text'] = rer_incident['message_text'].apply(html.unescape)\n",
    "rer_incident.drop_duplicates(subset=[\"disruption_id\"], inplace=True)\n",
    "rer_incident.drop(['tags', 'category', 'updated_at', 'channel_name'], axis=1, inplace=True) \n",
    "\n",
    "delays_metro.drop(['scheduled_arrival','scheduled_departure','arrival_difference','departure_difference'], axis=1, inplace=True)\n",
    "delays_metro['line_ref'] = delays_metro['line_ref'].str.replace('STIF:Line::', '', regex=False).str.rstrip(':')\n",
    "onTime_metro.drop(['scheduled_arrival','scheduled_departure','arrival_difference','departure_difference'], axis=1, inplace=True)\n",
    "onTime_metro['line_ref'] = onTime_metro['line_ref'].str.replace('STIF:Line::', '', regex=False).str.rstrip(':')\n",
    "\n",
    "onTime_metro['stop_reference'] = pd.to_numeric(onTime_metro['stop_reference'], errors='coerce')\n",
    "onTime_metro['stop_reference'] = onTime_metro['stop_reference'].fillna(0).astype('int64')\n",
    "onTime_rer['stop_reference'] = pd.to_numeric(onTime_rer['stop_reference'], errors='coerce')\n",
    "onTime_rer['stop_reference'] = onTime_rer['stop_reference'].fillna(0).astype('int64')\n",
    "\n",
    "mapping = dict(zip(name_filter, stops_filter))\n",
    "trafic2023_ratio['LIBELLE_ARRET_REA'] = trafic2023_ratio['LIBELLE_ARRET'].replace(mapping)\n",
    "trafic2023_ratio.drop([\"lda\"],axis=1, inplace=True)\n",
    "\n",
    "trafic2023_raw['LIBELLE_ARRET_REA'] = trafic2023_raw['LIBELLE_ARRET'].replace(mapping)\n",
    "trafic2023_raw.drop([\"lda\"],axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "69302686",
   "metadata": {},
   "outputs": [],
   "source": [
    "#filter dataset\n",
    "stops_data = stops_data[stops_data['ArRId'].isin(stops_filter)]\n",
    "\n",
    "metro_incident = metro_incident[\n",
    "    metro_incident['ref'].isin(map(str, stops_filter + lines_filter))\n",
    "]\n",
    "\n",
    "rer_incident = rer_incident[\n",
    "    rer_incident['ref'].isin(map(str, stops_filter + lines_filter))\n",
    "]\n",
    "\n",
    "trafic2023_ratio = trafic2023_ratio[trafic2023_ratio['LIBELLE_ARRET_REA'].isin(stops_filter)]\n",
    "\n",
    "trafic2023_raw = trafic2023_raw[trafic2023_raw['LIBELLE_ARRET_REA'].isin(stops_filter)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "afadb29f-88b3-4e5e-a454-3d0d6cc7fd77",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Merge datasets\n",
    "merged_metro = pd.concat([delays_metro, onTime_metro], ignore_index=True)\n",
    "merged_metro = pd.merge(merged_metro, stops_data, left_on='stop_reference', right_on='ArRId')\n",
    "merged_metro.drop(['ArRId', 'ArRName', 'ArRType', 'transport_mode', 'recorded_at_time'], axis=1, inplace=True) \n",
    "merged_metro = merged_metro.sort_values(by='real_arrival')\n",
    "\n",
    "merged_rer = pd.concat([delays_rer, onTime_rer], ignore_index=True)\n",
    "merged_rer = pd.merge(merged_rer, stops_data, left_on='stop_reference', right_on='ArRId')\n",
    "merged_rer.drop(['ArRId', 'ArRName', 'ArRType', 'transport_mode', 'recorded_at_time'],  axis=1, inplace=True)\n",
    "merged_rer = merged_rer.sort_values(by='scheduled_arrival')\n",
    "\n",
    "def date_format(df):\n",
    "    df['timestamp'] = pd.to_datetime(df['timestamp'].str.replace('Z', ''), errors='coerce')\n",
    "    df['timestamp'] = pd.to_datetime(df['timestamp'])\n",
    "    df['real_arrival'] = pd.to_datetime(df['real_arrival']).dt.strftime('%Y-%m-%d %H:%M:%S')\n",
    "    df['real_arrival'] = pd.to_datetime(df['real_arrival'])\n",
    "    df['real_departure'] = pd.to_datetime(df['real_departure']).dt.strftime('%Y-%m-%d %H:%M:%S')\n",
    "    df['real_departure'] = pd.to_datetime(df['real_departure'])\n",
    "\n",
    "\n",
    "def format_rer(df):\n",
    "    df['scheduled_arrival'] = pd.to_datetime(df['scheduled_arrival']).dt.strftime('%Y-%m-%d %H:%M:%S')\n",
    "    df['scheduled_arrival'] = pd.to_datetime(df['scheduled_arrival'])\n",
    "    df['scheduled_departure'] = pd.to_datetime(df['scheduled_departure']).dt.strftime('%Y-%m-%d %H:%M:%S')\n",
    "    df['scheduled_departure'] = pd.to_datetime(df['scheduled_departure'])\n",
    "    df.loc[(df['arrival_difference'] >= 5) | (df['departure_difference'] >= 5), 'departure_status'] = 'delayed'\n",
    "    df['nearest_datetime'] = df['scheduled_arrival'].combine_first(df['scheduled_departure'])\n",
    "\n",
    "date_format(merged_metro)\n",
    "date_format(merged_rer)\n",
    "format_rer(merged_rer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2cd4d3e7-3e72-4853-9080-8995cf45bea3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Clean Gas Price data\n",
    "def clean_gas_data(file_path, fuel_type):\n",
    "    # Load CSV file\n",
    "    df = pd.read_csv(file_path, skiprows=3, sep=';')  # Skip the first 3 metadata rows\n",
    "    df.rename(columns={df.columns[1]: f'{fuel_type}'}, inplace=True)\n",
    "    df = df.iloc[:, :-1]\n",
    "    return df\n",
    "    \n",
    "gas_95_df = clean_gas_data(\"./Online_Data/Gas/octane_95.csv\", \"95\")\n",
    "gas_98_df = clean_gas_data(\"./Online_Data/Gas/octane_98.csv\", \"98\")\n",
    "gas_e10_df = clean_gas_data(\"./Online_Data/Gas/95-E10.csv\", \"E10\")\n",
    "gazole_df = clean_gas_data(\"./Online_Data/Gas/gazole.csv\", \"gazole\")\n",
    "\n",
    "merged_metro = merged_metro.sort_values(by='real_arrival')\n",
    "merged_rer = merged_rer.sort_values(by='nearest_datetime')\n",
    "\n",
    "merged_rer['Période'] = pd.to_datetime(merged_rer['nearest_datetime']).dt.strftime('%Y-%m')\n",
    "merged_rer = merged_rer.merge(gas_95_df, on='Période', how='left')\n",
    "merged_rer = merged_rer.merge(gas_98_df, on='Période', how='left')\n",
    "merged_rer = merged_rer.merge(gas_e10_df, on='Période', how='left')\n",
    "merged_rer = merged_rer.merge(gazole_df, on='Période', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d1caf0ff-d837-4d5e-a3b7-bbdb8e9340fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def days_and_hols(df):\n",
    "    df['day'] = df['timestamp'].dt.date\n",
    "    df['day_of_week'] = df['timestamp'].dt.day_name()\n",
    "    df['is_weekend']= df['day_of_week'].isin(['Saturday', 'Sunday']).astype(int)\n",
    "\n",
    "days_and_hols(merged_rer)\n",
    "days_and_hols(merged_metro)\n",
    "\n",
    "\n",
    "merged_metro.drop(columns=['timestamp'], inplace=True)\n",
    "merged_rer.drop(columns=['Période', 'timestamp'], inplace=True)\n",
    "merged_rer = merged_rer[~merged_rer.duplicated(subset=merged_rer.columns.difference(['delayed_status']).tolist(), keep='last')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "577774b0-7de7-4753-a1c0-4c3868fad8dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#hourly_weather['date'] = pd.to_datetime(hourly_weather['date'])\n",
    "minutely_15_weather['date'] = pd.to_datetime(minutely_15_weather['date'])\n",
    "\n",
    "merged_metro = pd.merge_asof(merged_metro, \n",
    "                   minutely_15_weather, \n",
    "                   left_on='real_arrival', \n",
    "                   right_on='date', \n",
    "                   direction='nearest')\n",
    "\n",
    "merged_rer = pd.merge_asof(merged_rer, \n",
    "                   minutely_15_weather, \n",
    "                   left_on='nearest_datetime', \n",
    "                   right_on='date', \n",
    "                   direction='nearest')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "effacf6a-b7b8-44b7-9c61-45b2121dc758",
   "metadata": {},
   "outputs": [],
   "source": [
    "#split by stop\n",
    "CDG = merged_metro[merged_metro['stop_name'].isin(['Charles de Gaulle-Etoile'])]\n",
    "CDG = CDG.drop_duplicates(subset=['destination_name', 'real_arrival'], keep='first')\n",
    "\n",
    "SGP = merged_metro[merged_metro['stop_name'].isin(['Saint-Germain des Prés'])]\n",
    "SGP = SGP.drop_duplicates(subset=['destination_name', 'real_arrival'], keep='first')\n",
    "\n",
    "BL = merged_metro[merged_metro['stop_name'].isin(['Blanche'])]\n",
    "BL = BL.drop_duplicates(subset=['destination_name', 'real_arrival'], keep='first')\n",
    "\n",
    "SL = merged_metro[merged_metro['stop_name'].isin(['Saint-Lazare'])]\n",
    "SL = SL.drop_duplicates(subset=['destination_name', 'real_arrival'], keep='first')\n",
    "\n",
    "APK = merged_rer[merged_rer['stop_name'].isin(['Avenue du Président Kennedy'])]\n",
    "APK = APK.drop_duplicates(subset=['destination_name', 'scheduled_arrival'], keep='first')\n",
    "\n",
    "CLH = merged_rer[merged_rer['stop_name'].isin(['Châtelet - Les Halles'])]\n",
    "CLH = CLH.drop_duplicates(subset=['destination_name', 'scheduled_arrival'], keep='first')\n",
    "\n",
    "GBG = merged_rer[merged_rer['stop_name'].isin(['Gare de Buno Gironville'])]\n",
    "GBG = GBG.drop_duplicates(subset=['destination_name', 'scheduled_arrival'], keep='first')\n",
    "\n",
    "MP = merged_rer[merged_rer['stop_name'].isin(['Massy - Palaiseau'])]\n",
    "MP = MP.drop_duplicates(subset=['destination_name', 'scheduled_arrival'], keep='first')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "c00d4487-0a68-4337-9a25-34bbf92df6d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "CDG.to_csv('CDG.csv', index=False)\n",
    "SGP.to_csv('SGP.csv', index=False)\n",
    "BL.to_csv('BL.csv', index=False)\n",
    "SL.to_csv('SL.csv', index=False)\n",
    "APK.to_csv('APK.csv', index=False)\n",
    "CLH.to_csv('CLH.csv', index=False)\n",
    "GBG.to_csv('GBG.csv', index=False)\n",
    "MP.to_csv('MP.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "515f856d-6d6e-409f-9f41-f70c0647db6e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
